/**
 * Deck API - AI Service
 *
 * @file aiService.js
 * @description Provides services for AI-related actions.
 * 
 * This module interacts with AI models (Gemini and OpenAI) to tasks like sending prompt, uploading files and checking if file uploaded.
 * 
 * @module aiService
 * 
 * @requires ../config/geminiConfig.js
 * @requires ../schema/promptFlashCardSchema.js
 * 
 * @author Arthur M. Artugue
 * @created 2025-02-12
 * @updated 2025-03-20
 * 
 */

import { getModel, fileManager } from '../config/geminiConfig.js';
import { promptFlashCardSchema } from '../schema/promptFlashCardSchema.js'
import { moderatedFlashcardsSchema } from '../schema/flashcardModerationSchema.js';
// import { Threads } from 'openai/resources/beta/index.mjs';

/**
 * Sends a prompt to the Gemini model, optionally including a PDF file.
 * 
 * @async
 * @param {boolean} isTherePdf - Indicates whether a PDF file is included.
 * @param {string} prompt - The prompt text to be sent to the Gemini model.
 * @param {string} [filePath=""] - The path to the PDF file (if any).
 * @param {string} [fileExtension=""] - The file extension of the PDF.
 * @returns {Promise<string>} - The response content generated by the model.
 */
export async function sendPromptFlashcardGeneration(isTherePdf, prompt, filePath = "", fileExtension = "") {
    let attempt = 0;
    const MAX_RETRIES = 3; // Maximum retry attempts
    const BASE_DELAY = 1000; // Initial delay in ms (1 second)

    while (attempt < MAX_RETRIES) {
        try {
            console.log(`Attempt ${attempt + 1} to send prompt for flashcard generation...`);

            // Validate input parameters
            if (typeof isTherePdf !== "boolean") {
                throw new Error("Invalid argument: isTherePdf must be a boolean.");
            }
            if (typeof prompt !== "string" || prompt.trim() === "") {
                throw new Error("Invalid argument: prompt must be a non-empty string.");
            }
            if (isTherePdf && (typeof filePath !== "string" || filePath.trim() === "")) {
                throw new Error("Invalid argument: filePath must be a non-empty string when isTherePdf is true.");
            }
            if (isTherePdf && (typeof fileExtension !== "string" || fileExtension.trim() === "")) {
                throw new Error("Invalid argument: fileExtension must be a non-empty string when isTherePdf is true.");
            }

            let result;
            const model = getModel(promptFlashCardSchema, "gemini-2.0-flash");

            if (isTherePdf) {
                // Validate file extension
                const fileType = getMimeType(fileExtension);
                if (!fileType) {
                    throw new Error("Unsupported file type. Please provide a valid file extension.");
                }

                // Upload file and wait for activation
                const files = [await uploadToGemini(filePath, fileType)];
                await waitForFilesActive(files);

                // Ensure file upload was successful
                if (!files[0]?.uri) {
                    throw new Error("File upload failed. No URI received.");
                }

                result = await model.generateContent([
                    {
                        fileData: {
                            mimeType: files[0].mimeType,
                            fileUri: files[0].uri,
                        },
                    },
                    { text: prompt },
                ]);
            } else {
                result = await model.generateContent(prompt);
            }

            // Ensure response is valid
            if (!result?.response?.candidates?.[0]?.content?.parts?.[0]?.text) throw new Error("INVALID_RESPONSE_FORMAT");
            const response = JSON.parse(result.response.candidates[0].content.parts[0].text);
            if(!validateFlashcardResponse(response)) throw new Error("INVALID_RESPONSE_FORMAT");

            return {
                success: true,
                message: "Prompt was sent successfully",
                data: response,
            };

        } catch (error) {
            const retryableErrors = ["NetworkError", "TimeoutError", "ServiceUnavailable", "INVALID_RESPONSE_FORMAT"];
            console.error(`Error on attempt ${attempt + 1}: ${error.message}`);

            if (!retryableErrors.includes(error.name)) {
                console.error("Non-retryable error encountered:", error.message);
                return {
                    success: false,
                    message: error.message,
                    data: null,
                };
            }

            if (attempt === MAX_RETRIES - 1) {
                console.error("Max retry attempts reached. Returning failure.");
                return {
                    success: false,
                    message: error.message,
                    data: null,
                };
            }

            // Exponential backoff delay
            const delay = BASE_DELAY * Math.pow(2, attempt); // 1s, 2s, 4s...
            console.log(`Retrying in ${delay / 1000} seconds...`);
            await new Promise(resolve => setTimeout(resolve, delay));
        }
        attempt++; // Increment attempt count
    }
}

/**
 * Sends a prompt to the Gemini model, to do moderation task
 * 
 * @async
 * @param {string} prompt - The prompt text to be sent to the Gemini model.
 * @returns {Promise<string>} - The response content generated by the model.
 */
export async function sendPromptModeration(prompt) {
    let attempt = 0;
    const MAX_RETRIES = 3; // Maximum retry attempts
    const BASE_DELAY = 1000; // Initial delay in ms (1 second)

    while (attempt < MAX_RETRIES) {
        try {
            console.log(`Attempt ${attempt + 1} to send prompt for moderation...`);

            let result;
            const model = getModel(moderatedFlashcardsSchema, "gemini-2.0-flash");

            result = await model.generateContent(prompt);

            // Ensure response is valid
            if (!result?.response?.candidates?.[0]?.content?.parts?.[0]?.text) {
                throw new Error("Invalid response received from the model.");
            }

            const response = result.response.candidates[0].content.parts[0].text;
            return {
                data: JSON.parse(response),
            };

        } catch (error) {
            const retryableErrors = ["NetworkError", "TimeoutError", "ServiceUnavailable"];
            console.error(`Error on attempt ${attempt + 1}: ${error.message}`);

            if (!retryableErrors.includes(error.name)) {
                console.error("Non-retryable error encountered:", error.message);
                throw new Error("Non-retryable error encountered", error.message);
            }

            if (attempt === MAX_RETRIES - 1) {
                console.error("Max retry attempts reached. Returning failure.");
                throw new Error("Max retry attempts reached. Cause of error:", error.message);
            }

            // Exponential backoff delay
            const delay = BASE_DELAY * Math.pow(2, attempt); // 1s, 2s, 4s...
            console.log(`Retrying in ${delay / 1000} seconds...`);
            await new Promise(resolve => setTimeout(resolve, delay));
        }

        attempt++; // Increment attempt count
    }
}

/**
 * Sends a prompt to the Gemini model using prompt and inline data, to do task
 * 
 * @async
 * @param {object} schema - The reponse schema that the ai will follow
 * @param {string} prompt - The prompt text to be sent to the Gemini model.
 * @param {object} data - The data to be included in the prompt.
 * @returns {Promise<string>} - The response content generated by the model.
 */
export async function sendPromptInline(schema, prompt, data) {
    let attempt = 0;
    const MAX_RETRIES = 3; // Maximum retry attempts
    const BASE_DELAY = 1000; // Initial delay in ms (1 second)

    while (attempt < MAX_RETRIES) {
        try {
            console.log(`Attempt ${attempt + 1} to send inline prompt...`);

            let result;
            const model = getModel(schema, "gemini-2.0-flash");

            const textContent = data;
            const encoder = new TextEncoder();
            const textBuffer = encoder.encode(textContent);
            const base64Data = Buffer.from(textBuffer).toString('base64');
            result = await model.generateContent([
                {
                    inlineData: {
                        data: base64Data,
                        mimeType: "text/plain",
                    },
                },
                prompt ,
            ]);

            const inlineData = {
                inlineData: {
                    data: base64Data,
                    mimeType: "text/plain",
                }
            }
            const count = await countToken(null, [prompt, inlineData]);
            console.log(`Request token count is: ${count}`);
            
            // Ensure response is valid
            if (!result?.response?.candidates?.[0]?.content?.parts?.[0]?.text) {
                throw new Error("Invalid response received from the model.");
            }

            const response = result.response.candidates[0].content.parts[0].text;
            
            return {
                quiz_data: JSON.parse(response),
            };

        } catch (error) {
            console.log(error);
            
            const retryableErrors = ["NetworkError", "TimeoutError", "ServiceUnavailable"];
            console.error(`Error on attempt ${attempt + 1}: ${error.message}`);

            if (!retryableErrors.includes(error.name)) {
                console.error("Non-retryable error encountered:", error.message);
                throw new Error("Non-retryable error encountered", error.message);
            }

            if (attempt === MAX_RETRIES - 1) {
                console.error("Max retry attempts reached. Returning failure.");
                throw new Error("Max retry attempts reached. Cause of error:", error.message);
            }

            // Exponential backoff delay
            const delay = BASE_DELAY * Math.pow(2, attempt); // 1s, 2s, 4s...
            console.log(`Retrying in ${delay / 1000} seconds...`);
            await new Promise(resolve => setTimeout(resolve, delay));
        }

        attempt++; // Increment attempt count
    }
}

/**
 * Uploads a file to Gemini and returns the file object.
 * 
 * @async
 * @param {string} path - The path to the file to upload.
 * @param {string} mimeType - The MIME type of the file.
 * @returns {Promise<Object>} - The uploaded file object.
 */
export async function uploadToGemini(path, mimeType) {
    const uploadResult = await fileManager.uploadFile(path, {
        mimeType,
        displayName: path,
    });
    const file = uploadResult.file;
    console.log(`Uploaded file ${file.displayName} as: ${file.name}`);
    return file;
}

/**
 * Waits until all uploaded files are in the 'ACTIVE' state.
 * 
 * @async
 * @param {Array<Object>} files - List of uploaded file objects.
 * @throws {Error} - If a file fails to become active.
 */
export async function waitForFilesActive(files) {
    console.log(`Waiting for file ${file.name} to become active...`);
    for (const name of files.map((file) => file.name)) {
        let file = await fileManager.getFile(name);
        while (file.state === "PROCESSING") {
            process.stdout.write(".");
            await new Promise((resolve) => setTimeout(resolve, 10_000));
            file = await fileManager.getFile(name);
        }
        if (file.state !== "ACTIVE") {
            throw new Error(`File ${file.name} failed to process`);
        }
    }
    console.log("...all files ready\n");
}

/**
 * Counts the number of tokens in the given content using the specified AI model.
 *
 * @async
 * @param {string|null} [modelName=null] - The name of the AI model to use for token counting. Defaults to `null`, which selects the default model.
 * @param {string} content - The text content for which tokens need to be counted.
 * @returns {Promise<number>} - A promise that resolves to the total number of tokens in the content. Returns `0` if an error occurs.
 * @throws {Error} - Throws an error if `content` is not provided.
 */
export async function countToken(modelName = null, content){
    try {
        if (!content) {
            throw new Error("Content is required to count tokens.");
        }
        const model = getModel(null, modelName);
        const count = await model.countTokens(content);
        return count.totalTokens;
    } catch (error) {
        console.error(`Error counting tokens: ${error.message}`);
        return 0;
    }
}

/**
 * Validates if the given response follows the expected flashcard format.
 *
 * Expected format:
 * {
 *   "terms_and_definitions": [
 *     { "term": "Example Term", "definition": "Example Definition" },
 *     { "term": "Another Term", "definition": "Another Definition" }
 *   ]
 * }
 *
 * @param {Object} response - The response object to validate.
 * @param {Array<Object>} response.terms_and_definitions - An array of term-definition pairs.
 * @param {string} response.terms_and_definitions[].term - The term as a string.
 * @param {string} response.terms_and_definitions[].definition - The definition as a string.
 * @returns {boolean} - Returns `true` if the response is valid, otherwise `false`.
 */
function validateFlashcardResponse(response) {
    if (
        typeof response !== "object" ||
        !response.hasOwnProperty("terms_and_definitions") ||
        !Array.isArray(response.terms_and_definitions)
    ) {
        return false;
    }

    for (const item of response.terms_and_definitions) {
        if (
            typeof item !== "object" ||
            typeof item.term !== "string" ||
            typeof item.definition !== "string"
        ) {
            return false;
        }
    }

    return true;
}